# ğŸ¦– Dino AI Game â€“ NEAT + Pygame

An AI-powered version of the classic Chrome Dino game where autonomous agents learn to jump over obstacles using **NeuroEvolution of Augmenting Topologies (NEAT)** and **reinforcement learning**. Built with Python and Pygame.

---

## ğŸš€ Features

- ğŸ§  **NEAT Algorithm**: Evolving neural networks through natural selection.
- ğŸƒâ€â™‚ï¸ **Dynamic Obstacle Avoidance**: Agents learn to jump over cacti and birds.
- ğŸ“ˆ **Evolution Tracking**: Watch your AI improve over generations.
- ğŸ® **Pygame Visualization**: Real-time simulation of agents during training.
- ğŸ’¾ **Configurable Parameters**: Easily adjust genome count, mutation rates, etc.

---

## ğŸ›  Tech Stack

- **Python 3.x**
- **Pygame**
- **NEAT-Python**
- **NumPy** (optional for data handling)

---

## ğŸ“‚ Project Structure
ğŸ“ AI_Dino_Game/
â”œâ”€â”€ img/              # Sprites for dino, cactus, background, etc.
â”œâ”€â”€ dino.py              # Game logic using Pygame
â”œâ”€â”€ neat_config.txt      # Configuration for NEAT evolution
â”œâ”€â”€ main.py              # Main training loop using NEAT
â”œâ”€â”€ ai_player.py         # Dino agent controlled by neural network
â””â”€â”€ README.md            # Youâ€™re here!

---

## âš™ï¸ How It Works

- Each **Dino** is controlled by a neural network.
- Using sensors (like distance to cactus, obstacle speed), it decides when to **jump**.
- After each generation:
  - Fitness is calculated based on distance survived
  - Top performers reproduce using mutation & crossover
  - Poor performers are eliminated
- Over **100+ generations**, the AI evolves to play better and survive longer.

---


## Results
	-	#Achieved a high score of 10,000+ after ~100 generations.
	-	#Evolved agents show advanced jump timing and cactus prediction behavior.
